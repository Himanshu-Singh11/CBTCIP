Task 2

ChatBot:-

import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, Embedding, Dense
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

data = {
    "hi": "hello",
    "hello": "hi there!",
    "how are you?": "i am doing great, thanks!",
    "what is your name?": "i am your chatbot assistant.",
    "bye": "goodbye!",
    "2+2":"4",
    "who created you?": "i was created by Himanshu Singh using deep learning.",
    "thank you": "youâ€™re welcome!",
    "how old are you?": "i am timeless ",
    "what can you do?": "i can chat with you and help with basic questions.",
    "tell me a joke": "i would, but my humor chip is still under training",
    "good morning": "good morning! have a great day ahead!",
    "good night": "good night! sweet dreams.",
    "i need help": "sure! how can I help you?",
    "where are you from?": "i exist in the digital world.",
    "what is ai?": "ai means artificial intelligence â€” machines that think!",
    "what is machine learning?": "machine learning is how machines learn from data."
}

questions = list(data.keys())
answers = ['<start> ' + text + ' <end>' for text in data.values()]

tokenizer = Tokenizer(filters='')
tokenizer.fit_on_texts(questions + answers)
VOCAB_SIZE = len(tokenizer.word_index) + 1

question_seq = tokenizer.texts_to_sequences(questions)
answer_seq = tokenizer.texts_to_sequences(answers)

max_len_q = max(len(x) for x in question_seq)
max_len_a = max(len(x) for x in answer_seq)

encoder_input_data = pad_sequences(question_seq, maxlen=max_len_q, padding='post')
decoder_input_data = pad_sequences([a[:-1] for a in answer_seq], maxlen=max_len_a - 1, padding='post')
decoder_target_data = pad_sequences([a[1:] for a in answer_seq], maxlen=max_len_a - 1, padding='post')

EMB_DIM = 64
LATENT_DIM = 128

encoder_inputs = Input(shape=(max_len_q,))
enc_emb = Embedding(VOCAB_SIZE, EMB_DIM)(encoder_inputs)
encoder_outputs, state_h, state_c = LSTM(LATENT_DIM, return_state=True)(enc_emb)
encoder_states = [state_h, state_c]

decoder_inputs = Input(shape=(max_len_a - 1,))
dec_emb_layer = Embedding(VOCAB_SIZE, EMB_DIM)
dec_emb = dec_emb_layer(decoder_inputs)
decoder_lstm = LSTM(LATENT_DIM, return_sequences=True, return_state=True)
decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)
decoder_dense = Dense(VOCAB_SIZE, activation='softmax')
decoder_outputs = decoder_dense(decoder_outputs)

model = Model([encoder_inputs, decoder_inputs], decoder_outputs)
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')
model.fit([encoder_input_data, decoder_input_data],
          np.expand_dims(decoder_target_data, -1),
          batch_size=2,
          epochs=300,
          verbose=0)

print("âœ… Model training complete!")

encoder_model = Model(encoder_inputs, encoder_states)

decoder_state_input_h = Input(shape=(LATENT_DIM,))
decoder_state_input_c = Input(shape=(LATENT_DIM,))
decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]

dec_emb2 = dec_emb_layer(decoder_inputs)
decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)
decoder_states2 = [state_h2, state_c2]
decoder_outputs2 = decoder_dense(decoder_outputs2)

decoder_model = Model(
    [decoder_inputs] + decoder_states_inputs,
    [decoder_outputs2] + decoder_states2
)

def chat(input_text):
    input_seq = tokenizer.texts_to_sequences([input_text])
    input_seq = pad_sequences(input_seq, maxlen=max_len_q, padding='post')

    states_value = encoder_model.predict(input_seq)

    target_seq = np.array([[tokenizer.word_index['<start>']]])
    decoded_sentence = ''

    for _ in range(max_len_a):
        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)

        sampled_token_index = np.argmax(output_tokens[0, -1, :])
        sampled_word = tokenizer.index_word.get(sampled_token_index, '')

        if sampled_word == '<end>' or sampled_word == '':
            break

        decoded_sentence += sampled_word + ' '
        target_seq = np.array([[sampled_token_index]])
        states_value = [h, c]

    return decoded_sentence.strip()

print("\nðŸ¤– Chatbot is ready! Type 'exit' to stop.\n")
while True:
    user_input = input("You: ").strip().lower()
    if user_input == 'exit':
        print("Bot: Goodbye!")
        break
    response = chat(user_input)
    print("Bot:", response if response else "I don't understand.")
